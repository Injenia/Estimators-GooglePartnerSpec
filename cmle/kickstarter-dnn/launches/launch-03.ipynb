{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from tensorflow.python.lib.io.file_io import FileIO as open_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CSV=\"gs://ml-research-injenia/estimators/datasets/kickstarter-set/2016_trainset.csv\"\n",
    "EVALSET_CSV=\"gs://ml-research-injenia/estimators/datasets/kickstarter-set/2016_evalset.csv\"\n",
    "MODEL_DIR=\"gs://ml-research-injenia/estimators/trainings-kickstarter-v2/dnn-classifier/test03\"\n",
    "\n",
    "BATCH_SIZE = 15369\n",
    "TRAIN_STEPS= 2000000\n",
    "LEARNING_RATE=5.2897066388156818e-06\n",
    "L1_NORM=0.0\n",
    "L2_NORM=0.0\n",
    "\n",
    "HIDDEN_UNITS=[512,128,32,8]\n",
    "EMBEDDING_COLUMNS_SIZE=37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open_file(DATASET_CSV, \"r\") as f:\n",
    "    df = pd.read_csv(f)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open_file(EVALSET_CSV, \"r\") as f:\n",
    "    df_eval = pd.read_csv(f)\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open_file(os.path.join(MODEL_DIR,\"trainset.csv\"), \"w\") as f:\n",
    "    df.to_csv(f,index=False)\n",
    "with open_file(os.path.join(MODEL_DIR,\"evalset.csv\"), \"w\") as f:\n",
    "    df_eval.to_csv(f,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX=\"ID\"\n",
    "COLUMNS=[\n",
    "    \"category\",\n",
    "    \"main_category\",\n",
    "    \"state\",\n",
    "    \"country\",\n",
    "    \"timespan_days_scaled\",\n",
    "    \"goal_USD_scaled\",\n",
    "    \"goal_USD_log_scaled\"\n",
    "]\n",
    "LABEL_FIELD=\"state\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELD_DEFAULTS=[]\n",
    "FIELD_TYPES={}\n",
    "FIELD_CATEGORIES={}\n",
    "dtypes=dict(df.dtypes)\n",
    "for c in COLUMNS:\n",
    "    if(str(dtypes[c])==\"bool\"):\n",
    "        FIELD_DEFAULTS.append([0])\n",
    "        FIELD_TYPES[c]=\"bool\"\n",
    "    elif(str(dtypes[c])==\"object\"):\n",
    "        FIELD_DEFAULTS.append([\"NA\"])\n",
    "        FIELD_TYPES[c]=\"string\"\n",
    "        FIELD_CATEGORIES[c]=list(sorted(set(list(df[c].unique())+[\"NA\"])))\n",
    "    else:  \n",
    "        FIELD_DEFAULTS.append([0.0])\n",
    "        FIELD_TYPES[c]=\"number\"\n",
    "FIELD_CATEGORIES[LABEL_FIELD]=[x for x in FIELD_CATEGORIES[LABEL_FIELD] if x != \"NA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open_file(os.path.join(MODEL_DIR,\"data\",\"dataset_fields.json\"), \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"fields\":{\n",
    "                \"columns\" : COLUMNS,#[x for x in COLUMNS if x != LABEL_FIELD],\n",
    "                \"types\" : FIELD_TYPES,#{x:FIELD_TYPES[x] for x in FIELD_TYPES if x != LABEL_FIELD},\n",
    "                \"categories\" : FIELD_CATEGORIES,#{x:FIELD_CATEGORIES[x] for x in FIELD_CATEGORIES if x != LABEL_FIELD}\n",
    "            },\n",
    "            \"label\":{\n",
    "                \"column\" : LABEL_FIELD,\n",
    "                \"type\" : FIELD_TYPES[LABEL_FIELD],\n",
    "                \"categories\" : FIELD_CATEGORIES[LABEL_FIELD],\n",
    "            }\n",
    "        },\n",
    "        f\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open_file(os.path.join(MODEL_DIR,\"data\",\"tf_trainset.csv\"), \"w\") as f:\n",
    "    df[COLUMNS].to_csv(f, index=False)\n",
    "with open_file(os.path.join(MODEL_DIR,\"data\",\"tf_evalset.csv\"), \"w\") as f:\n",
    "    df_eval[COLUMNS].to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MODEL_DIR'] = str(MODEL_DIR)\n",
    "os.environ['TRAIN_STEPS'] = str(TRAIN_STEPS)\n",
    "os.environ['BATCH_SIZE'] = str(BATCH_SIZE)\n",
    "os.environ['LEARNING_RATE'] = str(LEARNING_RATE)\n",
    "os.environ['L1_NORM'] = str(L1_NORM)\n",
    "os.environ['L2_NORM'] = str(L2_NORM)\n",
    "\n",
    "os.environ['HIDDEN_UNITS']=\",\".join([str(x) for x in HIDDEN_UNITS])\n",
    "os.environ['EMBEDDING_COLUMNS_SIZE']=str(EMBEDDING_COLUMNS_SIZE)\n",
    "\n",
    "os.environ['BUCKET'] = \"ml-research-injenia\"\n",
    "os.environ['REGION'] = 'europe-west1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python -u trainer/task.py \\\n",
    "    --MODEL_DIR $MODEL_DIR \\\n",
    "    --TRAIN_STEPS $TRAIN_STEPS \\\n",
    "    --BATCH_SIZE $BATCH_SIZE   \\\n",
    "    --LEARNING_RATE $LEARNING_RATE \\\n",
    "    --L1_NORM $L1_NORM \\\n",
    "    --L2_NORM $L2_NORM \\\n",
    "    --HIDDEN_UNITS $HIDDEN_UNITS \\\n",
    "    --EMBEDDING_COLUMNS_SIZE $EMBEDDING_COLUMNS_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo $EMBEDDING_COLUMNS_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "JOBNAME=kickstarter_dnn_$(date -u +%y%m%d_%H%M%S)\n",
    "\n",
    "echo \"Launching training job ... trained model will be in $MODEL_DIR\"\n",
    "#gsutil -m rm -rf $OUTPUT_DIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$(pwd)/../trainer \\\n",
    "  --job-dir=$MODEL_DIR \\\n",
    "  --staging-bucket=gs://$BUCKET-staging \\\n",
    "  --runtime-version=\"1.6\" \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  -- \\\n",
    "   --MODEL_DIR=$MODEL_DIR \\\n",
    "   --TRAIN_STEPS $TRAIN_STEPS \\\n",
    "   --BATCH_SIZE $BATCH_SIZE   \\\n",
    "   --LEARNING_RATE $LEARNING_RATE \\\n",
    "   --L1_NORM $L1_NORM \\\n",
    "   --L2_NORM $L2_NORM  --HIDDEN_UNITS $HIDDEN_UNITS --EMBEDDING_COLUMNS_SIZE $EMBEDDING_COLUMNS_SIZE > ../logs/launch_dnn.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
